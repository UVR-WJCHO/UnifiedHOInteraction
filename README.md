# UnifiedHOInteraction

This repository contains instructions on generating custom dataset and code of the work `A Unified Hand and Gesture Tracking via Offloading Framework for Object-mediated Interaction in Wearable AR` presented at .


## Overview
UnifiedHOInteraction provides the following folders and models:

- `Device`: Device-side Unity project for Hololens 2
- `Server`: Server-side Python project
- `CustomDatasetToolkit`: Custom hand gesture dataset generation toolkit

- `Server/pretrained_models/`: ...


## Installation

- This code is tested with PyTorch 2.0.0 and Python 3.10.18 on Linux and Windows 11.
- Clone and install the following main packages.
    ```bash
    git clone git@github.com:UVR-WJCHO/UnifiedHOInteraction.git
    cd UnifiedHOInteraction
    pip install -r requirements.txt
    ```
	

## Download pretrained models
- TBD



## Run

### Server
- TBD

### Device
- TBD


## Create custom dataset and Train



## Acknowledgement
- This work was supported by Institute of Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korea government(MSIT) (RS-2019-II191270, WISE AR UI/UX Platform Development for Smartglasses)

- The sensing data acquisition using HoloLens 2 Research Mode was implemented with reference to [this project](https://github.com/jdibenes/hl2ss/).



## Lisense
WiseUI Applications are released under a MIT license. 
For a closed-source version of WiseUI's modules for commercial purposes, please contact the authors : uvrlab@kaist.ac.kr, woojin.cho@kaist.ac.kr

